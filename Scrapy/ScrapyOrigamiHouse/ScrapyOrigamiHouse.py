# 下载origamihouse.com网站里书籍的信息和图片from urllib.parse import urljoinimport chardetimport urllibimport refrom lxml import htmlimport requestsimport lxmlimport osfrom urllib import error__author__= 'Fan Xin (fanxin.hit@gmail.com)'class CrawlerWebSite(object):    def __init__(self,url):        print('init',url)        self.url = url        #Get Book URL from Home URL        self.collect_book_urls()    def collect_book_urls(self):        print('collect')        resp = requests.get(self.url)        encoding = chardet.detect(resp.content)["encoding"]        resp.encoding = encoding        link_list = re.findall(r'<a.*?href="(.*?)".*?>(.*?)</a>', resp.text, re.S | re.I)        for link in link_list:            book = urljoin(url, link[0]), link[1]            book_name = re.findall(r'.*?>(.*?)</span>',book[1])            if not book_name:                book_name = book[1]            print('link is ', book[0],'name is ',book_name)            self.download_book_image(book[0],book_name)    def download_book_image(self,book_url,book_name):        result = re.match('https:\/\/www\.origamihouse\.jp\/book\/original\/[^oh].*', book_url)        if result:            print('Book URL: ', book_url.split(',')[0])            new_page = book_url.split(',')[0]            # New Page is:  https://www.origamihouse.jp/book/original/nishikawa/nishikawa.html            url_first_position = new_page.rfind('/')            new_url_first = new_page[:url_first_position]            # Get Images from URL            response = urllib.request.urlopen(new_page)            result = response.read().decode('Shift_JIS')            html = lxml.html.fromstring(str(result))            title = html.xpath('//tr/td')            title = html.xpath('//div[3]/table[1]//tr/td[1]//img')            images = html.xpath('//a//img')            path = './books'            isExist = os.path.exists(path)            if not isExist:                os.mkdir(path)                print('创建成功')            try:                print('获取到的属性:', title[0].attrib)                book_name = title[0].get('alt')                if not book_name:                    book_name = '其他'                print('书籍名称:', book_name)                print('获取到的链接内容: ', title[0].get('src'))                print('主图片的链接: ', new_url_first + '/' + title[0].get('src'))                # make directory according to the book name                book_path = path + '/' + book_name                isExist = os.path.exists(book_path)                if not isExist:                    os.mkdir(book_path)                    print('创建成功')                print('其他图片')                for image in images:                    if re.findall(r"^[^\.][^https]", image.get('src')):                        print(image.get('src'))                        new_url_second = self.ChangeImageName(image.get('src'))                        new_url = new_url_first + '/' + new_url_second                        # print('链接： ', new_url)                        # 获取文件并保存                        urllib.request.urlretrieve(new_url, book_path + '/' + new_url_second)                print('----------------------------------------')            except IndexError:                pass            except error.HTTPError:                pass    def ChangeImageName(self, imagename):        # filter the following image name        # batou.gif        # s_DSC01025.jpg        # joisel_part1_s.jpg        # santaclaus_s.jpg        if re.findall("gif", imagename):            return imagename.replace('gif', 'jpg')        if re.findall("_s", imagename):            return imagename.replace('_s', '')        if re.findall("s_", imagename):            return imagename.replace('s_', '')        return imagenameif __name__ == '__main__':    print(os.path.realpath(__file__))    current_dir = os.path.dirname(os.path.realpath(__file__))    url = 'https://www.origamihouse.jp/book/original/house.html'    CrawlerWebSite(url)