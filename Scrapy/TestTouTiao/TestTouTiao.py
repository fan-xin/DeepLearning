import requestsimport reimport osfrom urllib.parse import urlencodefrom multiprocessing import Poolfrom hashlib import md5#爬取网页def get_page(offset):    headers = {"User-Agent": "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0)"}    #构建请求的链接    params = {        'aid':'24',        'app_name':'web_search',        'offset':offset,        'format':'json',        'autoload':'true',        'count':'20',        'cur_tab':'1',        'from':'search_tab',        'pd':'synthesis',        'en_qc':'1',        'timestamp':1561097632845,    }    # url='http://www.toutiao.com/search_content/?'+urlencode(params)    base_url = 'https://www.toutiao.com/api/search/content/?keyword=%E8%A1%97%E6%8B%8D'    #base_url = 'https://www.toutiao.com/api/search/content/?'    url = base_url + urlencode(params)    print('构建出的网页链接:', url)    try:        response = requests.get(url,headers=headers)        if response.status_code == 200:            #看一下返回的结构是否正确            print('返回的结果',response.json())            return response.json()    except requests.ConnectionError:        return Nonedef get_image(json):    print('get_image')    if json.get('data'):        data = json.get('data')        print('data is : ',data)        for item in data: #找到data中标题和图片的链接            print('success')            if item.get('cell_type') is not None:                continue            title = item.get('title')            images = item.get('image_list')            for image in images:                origin_image = re.sub("list","origin", image.get('url'))                print('图片的名称',origin_image)                yield {                    'image':origin_image,                    'title':title                }#保存图片def save_image(item):    img_path = 'img'+ os.path.sep + item.get('title') #os.path.sep是路径分隔符 /    #打印图片的地址    print(img_path)    if not os.path.exists(img_path): #如果不存在文件夹就创建一个        os.mkdir(img_path)    try:        response = requests.get(item.get('image'))        if response.status_code == 200:            file_path = img_path + os.path.sep + '{file_name}.{file_suffix}'.format(                file_name=md5(response.content).hexdigest(),                file_suffix='jpg'            )            if not os.path.exists(file_path):                print('success 3')                with open(file_path, 'wb') as f:                    f.write(response.content)                print('Downloaded image path is %s' % file_path)                print('success 4')            else:                print('Already Downloaded',file_path)    except requests.ConnectionError:        print('Failed to Save Image, item %s' %item)        # if response.status_code == 200:        #     file_path = '{0}/{1}.{2}'.format(item.get('title'),md5(response.content).hexdigest(),'jpg')        #     if not os.path.exists(file_path):        #         with open(file_path, 'wb') as f:        #             f.write(response.content)        #     else:        #         print('Already Downloaded',file_path)    except requests.ConnectionError:        print('Failed to Save Image')def main(offset):    #获取页面的信息    json = get_page(offset)    #对于获取到的每一个页面，提取页面里面的图片    for item in get_image(json):        #对于每一张提取出的图片，保存到文件夹中        print(item)        save_image(item)#分页的起始页数和终止页数GROUP_START = 1GROUP_END = 3if __name__ == '__main__':    #使用多线程    pool = Pool()    groups = ([x *20 for x in range(GROUP_START,GROUP_END+1)])    pool.map(main, groups)    pool.close()    pool.join()# 构建出的网页链接: https://www.toutiao.com/api/search/content/?keyword=%E8%A1%97%E6%8B%8Dautoload=true&en_qc=1&format=json&aid=24&from=search_tab&app_name=web_search&timestamp=1561097632845&count=20&cur_tab=1&offset=20&pd=synthesis# 构建出的网页链接: https://www.toutiao.com/api/search/content/?keyword=%E8%A1%97%E6%8B%8Dautoload=true&en_qc=1&format=json&aid=24&from=search_tab&app_name=web_search&timestamp=1561097632845&count=20&cur_tab=1&offset=40&pd=synthesis# 构建出的网页链接: https://www.toutiao.com/api/search/content/?keyword=%E8%A1%97%E6%8B%8Dautoload=true&en_qc=1&format=json&aid=24&from=search_tab&app_name=web_search&timestamp=1561097632845&count=20&cur_tab=1&offset=60&pd=synthesis# 返回的结果 {'return_count': 0, 'search_type': 2, 'cur_ts': 1561104951, 'request_id': '20190621161551010152037015078EA01', 'message': 'success', 'tab_rank': None, 'show_tabs': 1, 'count': 0, 'offset': 40, 'query_id': '6646929360982906120', 'keyword': '街拍autoload=true', 'pd': 'synthesis', 'log_pb': {'impr_id': '20190621161551010152037015078EA01'}, 'ab_fields': None, 'city': '东京', 'data_head': [{'url': 'sslocal://search?keyword=%E8%A1%97%E6%8B%8Dautoload%3Dtrue&from=&source=search_tab', 'challenge_code': 1366, 'keyword': '街拍autoload=true', 'cell_type': 71}], 'data': None, 'latency': 0, 'has_more': 0}# get_image# 返回的结果 {'return_count': 0, 'search_type': 2, 'cur_ts': 1561104951, 'request_id': '201906211615510100160601360772B43', 'message': 'success', 'tab_rank': None, 'show_tabs': 1, 'count': 0, 'offset': 60, 'query_id': '6646929360982906120', 'keyword': '街拍autoload=true', 'pd': 'synthesis', 'log_pb': {'impr_id': '201906211615510100160601360772B43'}, 'ab_fields': None, 'city': '东京', 'data_head': [{'url': 'sslocal://search?keyword=%E8%A1%97%E6%8B%8Dautoload%3Dtrue&from=&source=search_tab', 'challenge_code': 1366, 'keyword': '街拍autoload=true', 'cell_type': 71}], 'data': None, 'latency': 0, 'has_more': 0}# 返回的结果 {'return_count': 0, 'search_type': 2, 'cur_ts': 1561104951, 'request_id': '20190621161551010152028018078326F', 'message': 'success', 'tab_rank': None, 'show_tabs': 1, 'count': 0, 'offset': 80, 'query_id': '6646929360982906120', 'keyword': '街拍autoload=true', 'pd': 'synthesis', 'log_pb': {'impr_id': '20190621161551010152028018078326F'}, 'ab_fields': None, 'city': '东京', 'data_head': [{'url': 'sslocal://search?keyword=%E8%A1%97%E6%8B%8Dautoload%3Dtrue&from=&source=search_tab', 'challenge_code': 1366, 'keyword': '街拍autoload=true', 'cell_type': 71}], 'data': None, 'latency': 0, 'has_more': 0}# get_image# get_image