#抓取猫眼网站的电影信息#MaoYan Top 100 Movieimport requestsimport reimport jsonfrom requests.exceptions import RequestExceptionimport timedef get_one_page(url):    try:        headers = {            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36'        }        response = requests.get(url, headers= headers)        if response.status_code == 200:            return response.text        return None    except RequestException:        return Nonedef main():    url = 'http://maoyan.com/board/1'    html = get_one_page(url)    print(html)    for item in parse_one_page(html):        print(item)        write_to_file(item)#解析页面# <dd>#     <i class="board-index board-index-1">1</i>#     <a href="/films/1203" title="霸王别姬" class="image-link" data-act="boarditem-click" data-val="{movieId:1203}">#       <img src="//s3plus.meituan.net/v1/mss_e2821d7f0cfe4ac1bf9202ecf9590e67/cdn-prod/file:5788b470/image/loading_2.e3d934bf.png" alt="" class="poster-default" />#       <img data-src="https://p1.meituan.net/movie/20803f59291c47e1e116c11963ce019e68711.jpg@160w_220h_1e_1c" alt="霸王别姬" class="board-img" />#     </a>#     <div class="board-item-main">#       <div class="board-item-content">#               <div class="movie-item-info">#                   <p class="name"><a href="/films/1203" title="霸王别姬" data-act="boarditem-click" data-val="{movieId:1203}">霸王别姬</a></p>#                   <p class="star">#                         主演：张国荣,张丰毅,巩俐#                   </p>#                   <p class="releasetime">上映时间：1993-01-01</p>#               </div>#               <div class="movie-item-number score-num">#                   <p class="score"><i class="integer">9.</i><i class="fraction">5</i></p>#               </div>#       </div>#     </div># </dd>#.*?匹配尽可能少的字符def parse_one_page(html):    print('parse one page...')    pattern = re.compile(        '<dd>.*?board-index.*?>(.*?)</li>',re.S        # '<dd>.*?board-index.*?>(.*?)</i>.*?data-src="(.*?)".*?name.*?a.*?>(.*?)</a>'        # +'.*?star.*?">(.*?)</p>.*?releasetime.*?>(.*?)</p>.*?integer.*?>(.*?)</i>.*?fraction.*?>(.*?)</i>.*?</dd>',re.S    )    items = re.findall(pattern,html)    print('items is',items)    for item in items:        yield{            'index':item[0]            # 'image':item[1],            # 'title': item[2].strip(),            # 'star':item[3].strip()[3:] if len(item[3]) >3 else '',            # 'time':item[4].strip()[5:] if len(item[4]) >5 else '',            # 'score':item[5].strip()+item[6].strip()        }def write_to_file(content):    with open('result.txt','a', encoding='utf-8') as f:        print(type(json.dumps(content)))        f.write(json.dumps(content, ensure_ascii=False)+'\n')if __name__ == '__main__':    print('Beigin to scrapy 猫眼电影的电影榜单...')    # for i in range(10):    #     main(offset=i*10)    #     time.sleep(1)    main()